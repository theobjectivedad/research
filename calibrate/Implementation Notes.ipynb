{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69529352-cae2-4613-bb48-be308951342e",
   "metadata": {},
   "source": [
    "# TextEvolve Calabrate Research Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a69a63-6b7a-4247-a1ab-a93f592c9378",
   "metadata": {},
   "source": [
    "## New Capabilities\n",
    "\n",
    "Updated the ProTeGi *(pryzant2023automaticpromptoptimizationgradient)* optimize method to calabrate a prompt template $t$ to a set of calibration parameters $\\mathcal{D}_{cal}$ using Evaluate as the metrics function, $\\operatorname{m} \\triangleq \\operatorname{E}$\n",
    "\n",
    "## Beam Search Changes\n",
    "\n",
    "The initial prompt $p_0$ is now an initial prompt template $t_0$.\n",
    "\n",
    "Training data $\\mathcal{D}_{tr}$ is now a calibration dataset $\\mathcal{D}_{cal}$ that contains known template key/value replacements that we are training (calibrating) the prompt template on.\n",
    "\n",
    "The role of $B$ has changed since we are not optimizing against a set of labels, rather we are tracking beam performance against prompt template variations against mini-batches of $\\mathcal{D}_{cal}$\n",
    "\n",
    "Scores for all mini-batch elements are generated in parallel to take advantage of batch inferencing (updated interface to TextEvolve Evaluate).\n",
    "\n",
    "## Expansion Changes\n",
    "\n",
    "The \"gradients\", $g$, returned by $\\operatorname{E}$ are the natural-language debate history and explain the thought process of the debater agents during scoring.\n",
    "\n",
    "Expansions from $LLM_{\\sigma}$ remain a single operation\n",
    "\n",
    "## Selection Changes\n",
    "\n",
    "A new fast selection algorithm has been implemented. \n",
    "\n",
    "An early stopping mechanism exists at the search depth level where the calibration algorithm will skip remaining rounds if no new prompt templates are discoverd from the previous round. In practice this is likely to be rare and a tolerance may be needed to detect close / good enough results.\n",
    "\n",
    "\n",
    "## Additional Thoughts\n",
    "\n",
    "* As with deep learning validation, should we split apart D into train and validation records and keep them seperate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccab4c9-780b-4f69-b4b1-ff2eb23b5181",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "* How to ensure that the entire calibration dataset is seen? Is this even inportant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a68aac8-dc4b-497b-990e-6ee4f050b2de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## References\n",
    "\n",
    "```\n",
    "@article{dean2008mapreduce,\n",
    "  abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a <i>map</i> and a <i>reduce</i> function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},\n",
    "  acmid = {1327492},\n",
    "  added-at = {2012-06-19T17:23:52.000+0200},\n",
    "  address = {New York, NY, USA},\n",
    "  author = {Dean, Jeffrey and Ghemawat, Sanjay},\n",
    "  biburl = {https://www.bibsonomy.org/bibtex/2bff539224836d703c2d21141985fa1a3/jaeschke},\n",
    "  doi = {10.1145/1327452.1327492},\n",
    "  interhash = {b8a00982bf087c8543855897b7362a04},\n",
    "  intrahash = {bff539224836d703c2d21141985fa1a3},\n",
    "  issn = {0001-0782},\n",
    "  issue_date = {January 2008},\n",
    "  journal = {Communications of the ACM},\n",
    "  keywords = {},\n",
    "  month = jan,\n",
    "  number = 1,\n",
    "  numpages = {7},\n",
    "  pages = {107--113},\n",
    "  publisher = {ACM},\n",
    "  timestamp = {2012-06-19T17:23:52.000+0200},\n",
    "  title = {MapReduce: simplified data processing on large clusters},\n",
    "  url = {http://doi.acm.org/10.1145/1327452.1327492},\n",
    "  volume = 51,\n",
    "  year = 2008\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "@misc{pryzant2023automaticpromptoptimizationgradient,\n",
    "      title={Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search}, \n",
    "      author={Reid Pryzant and Dan Iter and Jerry Li and Yin Tat Lee and Chenguang Zhu and Michael Zeng},\n",
    "      year={2023},\n",
    "      eprint={2305.03495},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL},\n",
    "      url={https://arxiv.org/abs/2305.03495}, \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5030a-1c62-4085-846b-9c697eeda772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
